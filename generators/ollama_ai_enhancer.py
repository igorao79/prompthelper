#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
OLLAMA –ò–ò-–£–°–ò–õ–ò–¢–ï–õ–¨ –ü–†–û–ú–ü–¢–û–í 2025 - DEEPSEEK –ö–ê–ß–ï–°–¢–í–û! üß†‚ö°
–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π, –ª–æ–∫–∞–ª—å–Ω—ã–π –ò–ò-—É—Å–∏–ª–∏—Ç–µ–ª—å —Å –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ –∫—Ä–µ–¥–∏—Ç–∞–º–∏
DEEPSEEK = –ö–ê–ß–ï–°–¢–í–û + –°–ö–û–†–û–°–¢–¨!
"""

import requests
import json
import time
import random
import os
import subprocess
from typing import Dict, List, Optional

class OllamaAIEnhancer:
    """Ollama –ò–ò-—É—Å–∏–ª–∏—Ç–µ–ª—å - DEEPSEEK –ö–ê–ß–ï–°–¢–í–û! üß†‚ö°"""
    
    def __init__(self):
        self.ollama_url = "http://localhost:11434"
        self.api_endpoint = f"{self.ollama_url}/api/generate"
        
        # ‚ö° –ü–†–ò–ú–ï–ù–Ø–ï–ú –°–£–ü–ï–† –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò
        self._apply_speed_optimizations()
        
        # üß† DEEPSEEK –º–æ–¥–µ–ª–∏ –¥–ª—è –ö–ê–ß–ï–°–¢–í–ï–ù–ù–û–ô –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏!
        self.preferred_models = [
            "deepseek-r1:1.5b",             # üß† –°–ê–ú–ê–Ø –£–ú–ù–ê–Ø –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞!
            "deepseek-r1:8b",               # üß† –°–£–ü–ï–† –ö–ê–ß–ï–°–¢–í–û
            "llama3.2:3b-instruct-q4_0",   # Fallback –±—ã—Å—Ç—Ä—ã–π
            "gemma2:2b-instruct-q4_0",     # Fallback —É–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä—ã–π
            "qwen2.5:3b-instruct-q4_0",    # Fallback Alibaba
        ]
        
        # üéØ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
        self.enhancement_prompts = {
            'main': """Generate BUSINESS IMAGE prompt for: {theme}

Context: Professional business service
Requirements:
- English only
- Professional business environment  
- High quality, modern
- 15 words maximum
- NO technical equipment unless relevant

Output only the image prompt:""",
            
            'about': """Generate BUSINESS TOOLS prompt for: {theme}

Context: Professional equipment/workspace for this business
Requirements:
- English only
- Tools relevant to THIS specific business
- Professional setup
- 12 words maximum

Output only the image prompt:""",
            
            'review': """Generate CUSTOMER PHOTO prompt for: {theme}

Context: Happy customer of this business
Requirements:
- English only
- Smiling person only
- Satisfied customer expression
- 10 words maximum

Output only the image prompt:""",
            
            'favicon': """Generate SIMPLE ICON prompt for: {theme}

Context: Business logo/symbol
Requirements:
- English only
- Minimalist business icon
- Simple, clean design
- 8 words maximum

Output only the image prompt:"""
        }
        
        # ‚ö° –°–£–ü–ï–†-–ë–´–°–¢–†–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.fast_generation_options = {
            "temperature": 0.1,     # –ú–µ–Ω—å—à–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ = —Ç–æ—á–Ω–µ–µ
            "top_k": 10,           # –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–µ–Ω–Ω–æ—Å—Ç—å
            "top_p": 0.7,          # –¢–æ—á–Ω–æ—Å—Ç—å
            "repeat_penalty": 1.0, # –ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤
            "num_predict": 30,     # –ï—â–µ –∫–æ—Ä–æ—á–µ = –±—ã—Å—Ç—Ä–µ–µ
            "num_ctx": 512,        # –°–æ–≤—Å–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            "stop": ["\n", ".", "!", "Output:", "Prompt:"] # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–æ–ø
        }

    def _apply_speed_optimizations(self):
        """‚ö° –ü—Ä–∏–º–µ–Ω—è–µ–º –í–°–ï –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ Ollama"""
        speed_env = {
            "OLLAMA_FLASH_ATTENTION": "1",        # –ö–†–ò–¢–ò–ß–ù–û!
            "OLLAMA_KV_CACHE_TYPE": "q4_0",       # –ï—â–µ –±—ã—Å—Ç—Ä–µ–µ –∫–µ—à
            "OLLAMA_NUM_PARALLEL": "8",           # –ë–æ–ª—å—à–µ –ø–æ—Ç–æ–∫–æ–≤
            "OLLAMA_MAX_LOADED_MODELS": "1",      # –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å
            "OLLAMA_KEEP_ALIVE": "10m",           # –î–æ–ª—å—à–µ –≤ –ø–∞–º—è—Ç–∏
            "OLLAMA_GPU_LAYERS": "999",           # –í—Å–µ –Ω–∞ GPU
            "OLLAMA_HOST": "127.0.0.1:11434",     # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ö–æ—Å—Ç
            "OLLAMA_MAX_QUEUE": "20",             # –ë–æ–ª—å—à–µ –æ—á–µ—Ä–µ–¥—å
            "OLLAMA_CONCURRENT_REQUESTS": "4",    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        }
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        for key, value in speed_env.items():
            os.environ[key] = value
            
        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –°–£–ü–ï–†-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ Ollama!")

    def test_ollama_availability(self) -> bool:
        """‚ö° –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=1)
            return response.status_code == 200
        except:
            return False

    def get_best_available_model(self) -> Optional[str]:
        """üß† –ù–∞—Ö–æ–¥–∏–º –°–ê–ú–£–Æ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–£–Æ –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=2)
            if response.status_code == 200:
                available_models = [model["name"] for model in response.json().get("models", [])]
                
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ DeepSeek!
                for model in self.preferred_models:
                    if model in available_models:
                        print(f"üß† –ù–∞–π–¥–µ–Ω–∞ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø –º–æ–¥–µ–ª—å: {model}")
                        return model
                
                # Fallback –Ω–∞ –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é
                if available_models:
                    best = available_models[0]
                    print(f"üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å: {best}")
                    return best
        except:
            pass
        
        return None

    def create_enhanced_prompt(self, theme: str, prompt_type: str = "main") -> str:
        """üß† –ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ —Å DeepSeek"""
        if not self.test_ollama_availability():
            print("‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return self._fallback_prompt(theme, prompt_type)
        
        model = self.get_best_available_model()
        if not model:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback") 
            return self._fallback_prompt(theme, prompt_type)
        
        # ‚ö° –ë–´–°–¢–†–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        start_time = time.time()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç
            template = self.enhancement_prompts.get(prompt_type, self.enhancement_prompts['main'])
            user_prompt = template.format(theme=theme)
            
            # ‚ö° –°–£–ü–ï–†-–ë–´–°–¢–†–´–ô –∑–∞–ø—Ä–æ—Å –∫ Ollama
            payload = {
                "model": model,
                "prompt": user_prompt,
                "stream": False,
                "options": self.fast_generation_options
            }
            
            print(f"üß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {prompt_type} –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ {model}...")
            
            response = requests.post(
                self.api_endpoint, 
                json=payload, 
                timeout=10  # –ï—â–µ –∫–æ—Ä–æ—á–µ —Ç–∞–π–º–∞—É—Ç
            )
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get("response", "").strip()
                
                # üéØ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                cleaned = self._smart_clean_response(generated_text, theme, prompt_type)
                
                duration = time.time() - start_time
                print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø—Ä–æ–º–ø—Ç –∑–∞ {duration:.1f}—Å: {cleaned[:50]}...")
                
                return cleaned
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ Ollama: {response.status_code}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        # Fallback
        return self._fallback_prompt(theme, prompt_type)

    def _smart_clean_response(self, text: str, theme: str, prompt_type: str) -> str:
        """üéØ –£–ú–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        if not text:
            return self._fallback_prompt(theme, prompt_type)
        
        # ‚ö° –ë–´–°–¢–†–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –æ—Ç reasoning —Ç–µ–≥–æ–≤ DeepSeek
        text = text.replace("<think>", "").replace("</think>", "")
        text = text.replace("<thinking>", "").replace("</thinking>", "")
        text = text.replace("Output only the image prompt:", "")
        text = text.replace("English only", "")
        text = text.replace("Requirements:", "")
        text = text.replace("Context:", "")
        text = text.replace("Image prompt:", "")
        text = text.replace("Prompt:", "")
        text = text.strip()
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –±–µ–∑ reasoning
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ reasoning
            if line and not line.startswith('<') and not line.startswith('I need') and not line.startswith('Let me'):
                text = line
                break
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        text = text[:120]
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏
        text = text.strip('\'"')
        
        # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
        text = text.rstrip('.')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞
        russian_words = ['–∞–≤—Ç–æ–º–æ–±–∏–ª', '–º–∞—à–∏–Ω', '—É—Å–ª—É–≥', '–±–∏–∑–Ω–µ—Å', '–∫–æ–º–ø–∞–Ω–∏', '—Å–µ—Ä–≤–∏—Å', '—É—á–∞—Å—Ç–æ–∫', '–¥–∞—á–∞']
        for word in russian_words:
            if word in text.lower():
                return self._fallback_prompt(theme, prompt_type)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫
        if self._is_relevant_response(text, theme, prompt_type):
            return text if text else self._fallback_prompt(theme, prompt_type)
        else:
            print(f"‚ö†Ô∏è –ù–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return self._fallback_prompt(theme, prompt_type)

    def _is_relevant_response(self, text: str, theme: str, prompt_type: str) -> bool:
        """üéØ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ —Ç–µ–º–∞—Ç–∏–∫–µ"""
        text_lower = text.lower()
        theme_lower = theme.lower()
        
        # –î–ª—è –∑–∞–≥–æ—Ä–æ–¥–Ω—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤ –ù–ï –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç–µ—Ö–Ω–∏–∫–∏
        if '—É—á–∞—Å—Ç–∫' in theme_lower or '–¥–∞—á–∞' in theme_lower:
            tech_words = ['drone', 'scanner', '3d', 'camera', 'software', 'equipment', 'technology']
            if any(word in text_lower for word in tech_words):
                return False
        
        # –î–ª—è –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–∞ –î–û–õ–ñ–ù–´ –±—ã—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        if '–∞–≤—Ç–æ' in theme_lower and prompt_type == 'about':
            auto_words = ['car', 'vehicle', 'automotive', 'garage', 'tool', 'engine']
            if not any(word in text_lower for word in auto_words):
                return False
        
        return True

    def _fallback_prompt(self, theme: str, prompt_type: str) -> str:
        """üéØ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô fallback –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤"""
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ—Ä–æ–¥–Ω—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤
        if '—É—á–∞—Å—Ç–∫' in theme.lower() or '–¥–∞—á–∞' in theme.lower():
            fallbacks = {
                'main': "beautiful rural property with scenic countryside views and development potential",
                'about': "professional real estate consultation with property documents and site plans",
                'review': "satisfied property buyer smiling happily with rural landscape background",
                'favicon': "simple house icon with tree symbol minimalist rural property logo"
            }
            return fallbacks.get(prompt_type, fallbacks['main'])
        
        # –û–±—ã—á–Ω—ã–µ fallback –ø—Ä–æ–º–ø—Ç—ã
        fallbacks = {
            'main': f"professional {theme} business office modern high quality service",
            'about': f"modern {theme} professional equipment workspace tools",
            'review': f"satisfied customer smiling happy positive expression professional photo",
            'favicon': f"{theme} simple minimalist icon logo business symbol"
        }
        
        return fallbacks.get(prompt_type, fallbacks['main'])

def create_ollama_enhanced_prompts(theme_input: str) -> Dict[str, str]:
    """
    üß† DEEPSEEK –ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    """
    print(f"üß† DEEPSEEK Ollama –ò–ò-—É—Å–∏–ª–∏—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω –¥–ª—è: {theme_input}")
    
    enhancer = OllamaAIEnhancer()
    
    # üéØ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    prompts = {}
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        prompts['main'] = enhancer.create_enhanced_prompt(theme_input, 'main')
        prompts['about1'] = enhancer.create_enhanced_prompt(theme_input, 'about')
        prompts['about2'] = enhancer.create_enhanced_prompt(theme_input, 'about')
        prompts['about3'] = enhancer.create_enhanced_prompt(theme_input, 'about')
        
        # Review –ø—Ä–æ–º–ø—Ç—ã —Å –ª—é–¥—å–º–∏
        prompts['review1'] = enhancer.create_enhanced_prompt(theme_input, 'review')
        prompts['review2'] = enhancer.create_enhanced_prompt(theme_input, 'review')
        prompts['review3'] = enhancer.create_enhanced_prompt(theme_input, 'review')
        
        # –§–∞–≤–∏–∫–æ–Ω
        prompts['favicon'] = enhancer.create_enhanced_prompt(theme_input, 'favicon')
        
        print(f"‚úÖ DEEPSEEK Ollama –ò–ò-—É—Å–∏–ª–∏—Ç–µ–ª—å –∑–∞–≤–µ—Ä—à–∏–ª –æ–±—Ä–∞–±–æ—Ç–∫—É!")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ DEEPSEEK —É—Å–∏–ª–∏—Ç–µ–ª—è: {e}")
        # –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô fallback
        enhancer_fallback = OllamaAIEnhancer()
        prompts = {
            'main': enhancer_fallback._fallback_prompt(theme_input, 'main'),
            'about1': enhancer_fallback._fallback_prompt(theme_input, 'about'),
            'about2': enhancer_fallback._fallback_prompt(theme_input, 'about'),
            'about3': enhancer_fallback._fallback_prompt(theme_input, 'about'),
            'review1': enhancer_fallback._fallback_prompt(theme_input, 'review'),
            'review2': enhancer_fallback._fallback_prompt(theme_input, 'review'),
            'review3': enhancer_fallback._fallback_prompt(theme_input, 'review'),
            'favicon': enhancer_fallback._fallback_prompt(theme_input, 'favicon')
        }
    
    return prompts 